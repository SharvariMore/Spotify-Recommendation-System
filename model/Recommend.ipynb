import pandas as pd
import os
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.metrics import euclidean_distances
from scipy.spatial.distance import cdist
data_dir_base = '../data/output'
song_feats = '/audio_features.csv'
track_info = '/tracks.csv'
audio_feats = pd.read_csv(data_dir_base+song_feats)
tracks = pd.read_csv(data_dir_base + track_info)
tracks = tracks.drop_duplicates(['track_name']).reset_index(drop=True)
audio_feats = audio_feats[audio_feats.af_track_id.isin(tracks.track_id)].reset_index(drop=True)
audio_feats

import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

def calculate_cosine_similarity(features):
    # Calculate the cosine similarity matrix from the features
    return cosine_similarity(features)

def calculate_correlation_similarity(features):
    # Calculate the Pearson correlation matrix
    return features.corr()

from tqdm import tqdm 
def get_top_recommendations(df, top_n=10):
    # Assuming features are all columns except 'af_track_id'
    features = df.drop(['af_track_id','af_duration_ms'], axis=1)
    
    # Calculate similarity matrices
    cosine_sim = calculate_cosine_similarity(features)
    corr_sim = calculate_correlation_similarity(features)
    
    # Convert cosine similarity matrix to DataFrame to align with corr_sim
    cosine_sim_df = pd.DataFrame(cosine_sim, index=df.index, columns=df.index)
    
    # Calculate the average of cosine and correlation similarities
    avg_similarity = (cosine_sim_df) 
    
    # Prepare a dictionary to hold recommendations
    recommendations = {}
    
    # Get top recommendations for each song
    for idx in tqdm(df.index):
        track_id = df.at[idx, 'af_track_id']
        
        # Get similarity scores for this track with all others, skip the self-similarity at index 'idx'
        sim_scores = avg_similarity.iloc[idx]
        
        # Get indices of the songs with the highest similarity scores
        # argsort returns indices of sorted values; [::-1] reverses for descending order
        sorted_indices = sim_scores.argsort()[::-1][1:top_n+1]  # skip self by starting from 1
        
        # Get the track IDs of the most similar songs
        similar_tracks = df['af_track_id'].iloc[sorted_indices].tolist()
        
        # Store in the dictionary
        recommendations[track_id] = similar_tracks
        if idx%1000==0:
            print(idx)
    
    return recommendations

# Example DataFrame loading (replace with actual data loading code)
# df = pd.read_csv('path_to_your_data.csv')
import warnings
warnings.filterwarnings('ignore')
# Get recommendations
all_recommendations = get_top_recommendations(audio_feats)

# Convert to DataFrame
recommendations_df = pd.DataFrame(list(all_recommendations.items()), columns=['Track ID', 'Recommended Track IDs'])

# Display the result
print(recommendations_df.head())

recommendations_df_final = pd.concat([recommendations_df.drop('Recommended Track IDs',axis=1),\
                                      pd.DataFrame(recommendations_df['Recommended Track IDs'].values.tolist())],
                                     axis=1)
recommendations_df_final.columns = ['Track ID', 
                                    'recommended_track_1',
                                    'recommended_track_2',
                                    'recommended_track_3',
                                    'recommended_track_4',
                                    'recommended_track_5',
                                    'recommended_track_6',
                                    'recommended_track_7',
                                    'recommended_track_8',
                                    'recommended_track_9',
                                    'recommended_track_10']
recommendations_df_final.to_csv('recommendations.csv')

